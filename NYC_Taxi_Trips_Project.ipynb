{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnSaradar/NYC_Taxi_Driver_Analysis/blob/main/NYC_Taxi_Trips_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qFukHoK-620"
      },
      "source": [
        "# **Setup & Import Dask**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "HEuN6jE-_dyE"
      },
      "outputs": [],
      "source": [
        "# External dependencies\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfqhUHxYkVNB",
        "outputId": "193ee8c7-83e8-404c-f86f-94c2ceb52014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2022.12.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.3)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2023.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (23.1)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=0.3.10->dask) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rB0oma6dcxD"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "03Hn3sIQkYIP"
      },
      "outputs": [],
      "source": [
        "import dask.dataframe as dd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "IfyUB5X_Lfho"
      },
      "outputs": [],
      "source": [
        "zip_path = \"/content/drive/MyDrive/Datasets/Copy of nyc_taxi_data.zip\"\n",
        "extract_dir = '/content/sample_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "vZsR2XgqMmq2"
      },
      "outputs": [],
      "source": [
        "shutil.unpack_archive(zip_path, extract_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "m-XtNQdNMqzl"
      },
      "outputs": [],
      "source": [
        "df = dd.read_parquet('/content/sample_data/nyc_taxi_alt/*.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.npartitions"
      ],
      "metadata": {
        "id": "sh-nhUKz2l4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d445955-0255-42ed-bedf-bebc8e69b258"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "609"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MEs34FBkjs4"
      },
      "source": [
        "# **Discovering the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1TZmeuCpRhR"
      },
      "outputs": [],
      "source": [
        "from dask import delayed, compute, visualize, dataframe\n",
        "from dask.distributed import Client ,LocalCluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z78j-Z36RSr-"
      },
      "outputs": [],
      "source": [
        "print(\"Number of rows:\", df.shape[0].compute())\n",
        "print(\"Number of columns:\", len(df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1M-yZXcTpY6"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0495XDkT9l9"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRJCnciCqTjJ"
      },
      "outputs": [],
      "source": [
        "df.airport_fee.value_counts().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfTieX5OgIXM",
        "outputId": "35f23263-859d-465e-fccd-16330682ac7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0      126123945\n",
              "2.0       26414914\n",
              "3.0        7162781\n",
              "5.0        5554004\n",
              "0.0        3482482\n",
              "6.0        3425107\n",
              "4.0        3274587\n",
              "7.0            809\n",
              "8.0            524\n",
              "9.0            359\n",
              "96.0             1\n",
              "112.0            1\n",
              "Name: passenger_count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.passenger_count.value_counts().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaFvVHQ-wXiQ",
        "outputId": "6bd75824-fe74-4e93-d8b8-eb1c9f94481d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 2.50    145092336\n",
              " 0.00     14554138\n",
              "-2.50       452796\n",
              " 0.75         1195\n",
              " 2.75          673\n",
              " 0.50           44\n",
              " 1.00           25\n",
              "-0.75            9\n",
              " 1.50            4\n",
              " 0.80            2\n",
              "-1.50            1\n",
              " 0.30            1\n",
              " 1.80            1\n",
              " 2.25            1\n",
              " 3.00            1\n",
              "Name: congestion_surcharge, dtype: int64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.congestion_surcharge.value_counts().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "d1xt9W26rd-Q",
        "outputId": "2347a644-fce7-4e97-c925-9070a95102f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-91fc3967-e6a6-4cd8-a899-54c8ac559a02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>PULocationID</th>\n",
              "      <th>DOLocationID</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>congestion_surcharge</th>\n",
              "      <th>airport_fee</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.754395e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.754395e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.793117e+08</td>\n",
              "      <td>1.706512e+08</td>\n",
              "      <td>6.355071e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.671094e+00</td>\n",
              "      <td>1.492676e+00</td>\n",
              "      <td>4.405538e+00</td>\n",
              "      <td>1.143369e+00</td>\n",
              "      <td>1.637911e+02</td>\n",
              "      <td>1.617755e+02</td>\n",
              "      <td>1.349501e+00</td>\n",
              "      <td>1.262162e+01</td>\n",
              "      <td>1.064549e+00</td>\n",
              "      <td>4.952468e-01</td>\n",
              "      <td>3.319861e+00</td>\n",
              "      <td>4.097364e-01</td>\n",
              "      <td>3.020870e-01</td>\n",
              "      <td>1.969599e+01</td>\n",
              "      <td>2.241222e+00</td>\n",
              "      <td>8.722807e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.698158e-01</td>\n",
              "      <td>1.119885e+00</td>\n",
              "      <td>4.219229e+02</td>\n",
              "      <td>2.890464e+00</td>\n",
              "      <td>6.599441e+01</td>\n",
              "      <td>7.044308e+01</td>\n",
              "      <td>7.198644e-01</td>\n",
              "      <td>1.050185e+04</td>\n",
              "      <td>3.736028e+01</td>\n",
              "      <td>3.733934e+01</td>\n",
              "      <td>1.050032e+04</td>\n",
              "      <td>1.847462e+00</td>\n",
              "      <td>6.781555e-02</td>\n",
              "      <td>1.986252e+02</td>\n",
              "      <td>7.857634e-01</td>\n",
              "      <td>3.212864e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-3.726453e+04</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-1.333914e+08</td>\n",
              "      <td>-6.000000e+01</td>\n",
              "      <td>-5.500000e-01</td>\n",
              "      <td>-4.932200e+02</td>\n",
              "      <td>-9.999000e+01</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-2.567800e+03</td>\n",
              "      <td>-2.500000e+00</td>\n",
              "      <td>-1.250000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.390000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.370000e+02</td>\n",
              "      <td>1.320000e+02</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>8.500000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e-01</td>\n",
              "      <td>1.280000e+01</td>\n",
              "      <td>2.500000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.530000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.630000e+02</td>\n",
              "      <td>1.630000e+02</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.250000e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>2.340000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e-01</td>\n",
              "      <td>1.716000e+01</td>\n",
              "      <td>2.500000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>6.420000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.360000e+02</td>\n",
              "      <td>2.360000e+02</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>2.610000e+01</td>\n",
              "      <td>2.750000e+00</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>4.820000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e-01</td>\n",
              "      <td>3.444000e+01</td>\n",
              "      <td>2.500000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.120000e+02</td>\n",
              "      <td>3.896785e+05</td>\n",
              "      <td>9.900000e+01</td>\n",
              "      <td>2.650000e+02</td>\n",
              "      <td>2.650000e+02</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>9.983100e+05</td>\n",
              "      <td>5.000008e+05</td>\n",
              "      <td>5.000005e+05</td>\n",
              "      <td>1.333914e+08</td>\n",
              "      <td>3.288000e+03</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.084772e+06</td>\n",
              "      <td>4.500000e+00</td>\n",
              "      <td>1.250000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91fc3967-e6a6-4cd8-a899-54c8ac559a02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91fc3967-e6a6-4cd8-a899-54c8ac559a02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91fc3967-e6a6-4cd8-a899-54c8ac559a02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           VendorID  passenger_count  trip_distance    RatecodeID  \\\n",
              "count  1.793117e+08     1.754395e+08   1.793117e+08  1.754395e+08   \n",
              "mean   1.671094e+00     1.492676e+00   4.405538e+00  1.143369e+00   \n",
              "std    4.698158e-01     1.119885e+00   4.219229e+02  2.890464e+00   \n",
              "min    1.000000e+00     0.000000e+00  -3.726453e+04  1.000000e+00   \n",
              "25%    2.000000e+00     1.000000e+00   1.390000e+00  1.000000e+00   \n",
              "50%    2.000000e+00     1.000000e+00   2.530000e+00  1.000000e+00   \n",
              "75%    2.000000e+00     2.000000e+00   6.420000e+00  1.000000e+00   \n",
              "max    2.000000e+00     1.120000e+02   3.896785e+05  9.900000e+01   \n",
              "\n",
              "       PULocationID  DOLocationID  payment_type   fare_amount         extra  \\\n",
              "count  1.793117e+08  1.793117e+08  1.793117e+08  1.793117e+08  1.793117e+08   \n",
              "mean   1.637911e+02  1.617755e+02  1.349501e+00  1.262162e+01  1.064549e+00   \n",
              "std    6.599441e+01  7.044308e+01  7.198644e-01  1.050185e+04  3.736028e+01   \n",
              "min    1.000000e+00  1.000000e+00  1.000000e+00 -1.333914e+08 -6.000000e+01   \n",
              "25%    1.370000e+02  1.320000e+02  1.000000e+00  8.500000e+00  0.000000e+00   \n",
              "50%    1.630000e+02  1.630000e+02  1.000000e+00  1.250000e+01  1.000000e+00   \n",
              "75%    2.360000e+02  2.360000e+02  4.000000e+00  2.610000e+01  2.750000e+00   \n",
              "max    2.650000e+02  2.650000e+02  5.000000e+00  9.983100e+05  5.000008e+05   \n",
              "\n",
              "            mta_tax    tip_amount  tolls_amount  improvement_surcharge  \\\n",
              "count  1.793117e+08  1.793117e+08  1.793117e+08           1.793117e+08   \n",
              "mean   4.952468e-01  3.319861e+00  4.097364e-01           3.020870e-01   \n",
              "std    3.733934e+01  1.050032e+04  1.847462e+00           6.781555e-02   \n",
              "min   -5.500000e-01 -4.932200e+02 -9.999000e+01          -1.000000e+00   \n",
              "25%    5.000000e-01  1.000000e+00  0.000000e+00           3.000000e-01   \n",
              "50%    5.000000e-01  2.340000e+00  0.000000e+00           3.000000e-01   \n",
              "75%    5.000000e-01  4.820000e+00  0.000000e+00           3.000000e-01   \n",
              "max    5.000005e+05  1.333914e+08  3.288000e+03           1.000000e+00   \n",
              "\n",
              "       total_amount  congestion_surcharge   airport_fee  \n",
              "count  1.793117e+08          1.706512e+08  6.355071e+07  \n",
              "mean   1.969599e+01          2.241222e+00  8.722807e-02  \n",
              "std    1.986252e+02          7.857634e-01  3.212864e-01  \n",
              "min   -2.567800e+03         -2.500000e+00 -1.250000e+00  \n",
              "25%    1.280000e+01          2.500000e+00  0.000000e+00  \n",
              "50%    1.716000e+01          2.500000e+00  0.000000e+00  \n",
              "75%    3.444000e+01          2.500000e+00  0.000000e+00  \n",
              "max    1.084772e+06          4.500000e+00  1.250000e+00  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Oo8Mgt9xnEZ",
        "outputId": "4d8c50a4-a12f-449d-9fcf-00b8c8136487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    122751631\n",
              "2     40466949\n",
              "3       758470\n",
              "4       545424\n",
              "5           17\n",
              "Name: payment_type, dtype: int64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.payment_type.value_counts().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfXeZvLdfmQj"
      },
      "source": [
        "# Cleaning the Missing & Outlier Values "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyGg4xPlHdOG"
      },
      "source": [
        "## Passanger Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyXZcwbgdSrY",
        "outputId": "6c819583-c972-49ae-f85e-a62e2e79f6a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:39845\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:33019\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:39467'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:38447'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:44537', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:44537\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:40698\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:37699', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37699\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:40706\n",
            "INFO:distributed.scheduler:Receive client connection: Client-25a4edc0-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:40720\n",
            "INFO:distributed.scheduler:Remove client Client-25a4edc0-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:40720; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-25a4edc0-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-25a4edc0-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:39467'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:38447'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:40698; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:44537', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:44537\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:40706; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:37699', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:37699\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['passenger_count'] <= 4])\n",
        "\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNF-nrB3M4hP"
      },
      "source": [
        "## Trip Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnQlsrP8ZuHY",
        "outputId": "917861c3-ce4d-44cc-8774-8c7c16549ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:45655\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:42503\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:43529'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:42441'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:41089', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:41089\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:38420\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:38137', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:38137\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:38436\n",
            "INFO:distributed.scheduler:Receive client connection: Client-26a9997f-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:38438\n",
            "INFO:distributed.scheduler:Remove client Client-26a9997f-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:38438; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-26a9997f-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-26a9997f-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:43529'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:42441'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:38420; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:41089', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:41089\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:38436; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:38137', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:38137\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['trip_distance'] > 0])\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC_2PbVKQUDv"
      },
      "source": [
        "## Airport Fee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "bqlLxtBRQVub"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "df = df.loc[~df['airport_fee'].isin([0.50, -1.25])]\n",
        "df['airport_fee'] = df['airport_fee'].fillna(0.0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E26zcyb6yG-E"
      },
      "source": [
        "## RatecodeID & store_and_fwd_flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "uM1ROYl0ahBn"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "df = df.dropna(subset=['RatecodeID', 'store_and_fwd_flag'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYT214-VyTAe"
      },
      "source": [
        "##Congestion Surcharge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "If19yzQ4ahu1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "df = df.loc[~df['congestion_surcharge'].isin([-2.50, 0.50,1.00 ,-0.75 , 1.50  ,0.80  , -1.50  ,0.30  , 1.80 ,2.25  ,           3.00 ])]\n",
        "df['congestion_surcharge'] = df['congestion_surcharge'].fillna(2.50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaQrFomjy57y"
      },
      "source": [
        "## Fare Amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwtD5el5y5H4",
        "outputId": "4012338b-9453-45c5-f423-bf23cc5c9194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:36867\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:35261\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:45219'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:44181'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:39293', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:39293\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:39410\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:37509', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37509\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:39414\n",
            "INFO:distributed.scheduler:Receive client connection: Client-27b22ed6-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:39418\n",
            "INFO:distributed.scheduler:Remove client Client-27b22ed6-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:39418; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-27b22ed6-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-27b22ed6-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:45219'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:44181'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:39414; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:37509', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:37509\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:39410; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:39293', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:39293\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['fare_amount'] > 0])\n",
        "\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ODWrOx0AyR"
      },
      "source": [
        "## Extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhCsJH5-z_w9",
        "outputId": "8680f8cf-350e-4a34-eafb-8100a94e64ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:38709\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:43003\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:45009'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:45775'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:33739', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:33739\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46250\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:46707', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:46707\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46264\n",
            "INFO:distributed.scheduler:Receive client connection: Client-28a13549-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46280\n",
            "INFO:distributed.scheduler:Remove client Client-28a13549-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:46280; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-28a13549-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-28a13549-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:45009'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:45775'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:46264; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:46707', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:46707\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:46250; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:33739', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:33739\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['extra'] >= 0])\n",
        "\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hzGkrfR0I9x"
      },
      "source": [
        "##MTA Tax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXnQvx-m0Gvf",
        "outputId": "797334e4-26c8-4a96-96bd-82d254ac09a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:41773\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:43645\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:44227'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:38247'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:37969', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37969\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:35416\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:35699', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:35699\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:35424\n",
            "INFO:distributed.scheduler:Receive client connection: Client-2a2c2fc6-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:35426\n",
            "INFO:distributed.scheduler:Remove client Client-2a2c2fc6-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:35426; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-2a2c2fc6-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-2a2c2fc6-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:44227'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:38247'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:35424; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:35699', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:35699\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:35416; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:37969', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:37969\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['mta_tax'] >= 0])\n",
        "\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne4EuyYs0O_h"
      },
      "source": [
        "##Improvement Surcharge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4j9DwuF0WH2",
        "outputId": "cc1e4978-5928-4cb9-b8e5-2496efef5637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:44995\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:34317\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:46695'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:38067'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:41371', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:41371\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:33068\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:37371', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37371\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:33078\n",
            "INFO:distributed.scheduler:Receive client connection: Client-2b5c851c-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:33086\n",
            "INFO:distributed.scheduler:Remove client Client-2b5c851c-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33086; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-2b5c851c-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-2b5c851c-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:46695'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:38067'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33068; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:41371', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:41371\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33078; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:37371', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:37371\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['improvement_surcharge'] >= 0])\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-WzBuND0h2x"
      },
      "source": [
        "## Tip Amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trzy4RgC0amS",
        "outputId": "5348428d-1296-432c-adf6-b0a7c71161d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:39733\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:39595\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:34067'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:32989'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:36461', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:36461\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46508\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:46545', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:46545\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46498\n",
            "INFO:distributed.scheduler:Receive client connection: Client-2c44b95c-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46512\n",
            "INFO:distributed.scheduler:Remove client Client-2c44b95c-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:46512; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-2c44b95c-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-2c44b95c-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:34067'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:32989'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:46508; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:36461', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:36461\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:46498; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:46545', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:46545\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['tip_amount'] >= 0])\n",
        "\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SMGn0ej0kl5"
      },
      "source": [
        "## Tolls Amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0O5Kbdl0nDt",
        "outputId": "af98d8b1-1429-48a0-9233-61bf63e4ef07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:35037\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:44981\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:43773'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:40731'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:40903', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:40903\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:44366\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:44547', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:44547\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:44376\n",
            "INFO:distributed.scheduler:Receive client connection: Client-2d2c1e16-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:44384\n",
            "INFO:distributed.scheduler:Remove client Client-2d2c1e16-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:44384; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-2d2c1e16-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-2d2c1e16-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:43773'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:40731'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:44366; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:40903', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:40903\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:44376; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:44547', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:44547\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['tolls_amount'] >= 0])\n",
        "\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rkmflkW0npF"
      },
      "source": [
        "##Total Amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb22He5E0zer",
        "outputId": "b157aa5e-eaaa-4ed9-d808-c7607b940faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:40115\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:45641\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:40959'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:41483'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:43205', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:43205\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:33944\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:44893', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:44893\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:33946\n",
            "INFO:distributed.scheduler:Receive client connection: Client-2e1a055d-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:33954\n",
            "INFO:distributed.scheduler:Remove client Client-2e1a055d-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33954; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-2e1a055d-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-2e1a055d-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:40959'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:41483'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33944; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:43205', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:43205\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33946; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:44893', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:44893\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df = df.map_partitions(lambda partition: partition.loc[partition['total_amount'] > 0])\n",
        "\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing all the Cleaning Operations"
      ],
      "metadata": {
        "id": "NQjMNILs-97s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df.compute()\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jWBz4phR_EPk",
        "outputId": "5d176115-d14d-4ebb-ee78-4e90e9acb08c"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:38583\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:35759\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:39847'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:44631'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:44965', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:44965\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46762\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:34491', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:34491\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46774\n",
            "INFO:distributed.scheduler:Receive client connection: Client-2ef2311a-0876-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:46784\n",
            "2023-06-11 16:47:59,698 - distributed.core - ERROR - Exception while handling op gather\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/core.py\", line 820, in _handle_comm\n",
            "    result = await result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/scheduler.py\", line 5654, in gather\n",
            "    data, missing_keys, missing_workers = await gather_from_workers(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\", line 80, in gather_from_workers\n",
            "    r = await c\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/worker.py\", line 2870, in get_data_from_worker\n",
            "    return await retry_operation(_get_data, operation=\"get_data_from_worker\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\", line 400, in retry_operation\n",
            "    return await retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\", line 385, in retry\n",
            "    return await coro()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/worker.py\", line 2850, in _get_data\n",
            "    response = await send_recv(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/core.py\", line 1013, in send_recv\n",
            "    raise Exception(response[\"exception_text\"])\n",
            "Exception: AssertionError()\n",
            "ERROR:distributed.core:Exception while handling op gather\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/core.py\", line 820, in _handle_comm\n",
            "    result = await result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/scheduler.py\", line 5654, in gather\n",
            "    data, missing_keys, missing_workers = await gather_from_workers(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\", line 80, in gather_from_workers\n",
            "    r = await c\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/worker.py\", line 2870, in get_data_from_worker\n",
            "    return await retry_operation(_get_data, operation=\"get_data_from_worker\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\", line 400, in retry_operation\n",
            "    return await retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\", line 385, in retry\n",
            "    return await coro()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/worker.py\", line 2850, in _get_data\n",
            "    response = await send_recv(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/core.py\", line 1013, in send_recv\n",
            "    raise Exception(response[\"exception_text\"])\n",
            "Exception: AssertionError()\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='get-data-from-tcp://127.0.0.1:44965' coro=<get_data_from_worker() done, defined at /usr/local/lib/python3.10/dist-packages/distributed/worker.py:2821> exception=Exception('AssertionError()')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/worker.py\", line 2870, in get_data_from_worker\n",
            "    return await retry_operation(_get_data, operation=\"get_data_from_worker\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\", line 400, in retry_operation\n",
            "    return await retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\", line 385, in retry\n",
            "    return await coro()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/worker.py\", line 2850, in _get_data\n",
            "    response = await send_recv(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/distributed/core.py\", line 1013, in send_recv\n",
            "    raise Exception(response[\"exception_text\"])\n",
            "Exception: AssertionError()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-32e4b3729233>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3123\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3124\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3125\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3126\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3127\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   2295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                         \u001b[0;31m# Save the exception for later. It's important that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2184\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2186\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather_remote\u001b[0;34m(self, direct, local_worker)\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# ask scheduler to gather data for us\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mretry_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\u001b[0m in \u001b[0;36mretry_operation\u001b[0;34m(coro, operation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distributed.comm.retry.delay.max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0;31m     return await retry(\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\u001b[0m in \u001b[0;36mretry\u001b[0;34m(coro, count, delay_min, delay_max, jitter_fraction, retry_on_exceptions, operation)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mdelay\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjitter_fraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/core.py\u001b[0m in \u001b[0;36msend_recv_from_rpc\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mprev_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ConnectionPool.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0msend_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/core.py\u001b[0m in \u001b[0;36msend_recv\u001b[0;34m(comm, reply, serializers, deserializers, **kwargs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exception_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/core.py\u001b[0m in \u001b[0;36m_handle_comm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m                             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                             raise RuntimeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/scheduler.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5652\u001b[0m                 \u001b[0mwho_has\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5654\u001b[0;31m         data, missing_keys, missing_workers = await gather_from_workers(\n\u001b[0m\u001b[1;32m   5655\u001b[0m             \u001b[0mwho_has\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5656\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\u001b[0m in \u001b[0;36mgather_from_workers\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoroutines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mmissing_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/worker.py\u001b[0m in \u001b[0;36mget_data_from_worker\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2868\u001b[0m             \u001b[0mrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2870\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mretry_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"get_data_from_worker\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\u001b[0m in \u001b[0;36mretry_operation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distributed.comm.retry.delay.max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0;31m     return await retry(\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/utils_comm.py\u001b[0m in \u001b[0;36mretry\u001b[0;34m()\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mdelay\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjitter_fraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/worker.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2848\u001b[0m         \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Ephemeral Worker->Worker for gather\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2850\u001b[0;31m             response = await send_recv(\n\u001b[0m\u001b[1;32m   2851\u001b[0m                 \u001b[0mcomm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2852\u001b[0m                 \u001b[0mserializers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserializers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distributed/core.py\u001b[0m in \u001b[0;36msend_recv\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exception_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: AssertionError()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Results"
      ],
      "metadata": {
        "id": "RWFby9eF_UBV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlt4AlnD1Yhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5f0e83-fc52-4fcd-bbdb-aa889fe8791e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:35225\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:41523\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:42511'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:46457'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:46351', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:46351\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:58178\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:36559', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:36559\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:58192\n",
            "INFO:distributed.scheduler:Receive client connection: Client-20c12217-0855-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:58198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows , After Cleaning: 163966708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:Remove client Client-20c12217-0855-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:58198; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-20c12217-0855-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-20c12217-0855-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:42511'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:46457'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:58178; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:46351', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:46351\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:58192; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:36559', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:36559\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "print(\"Number of rows , After Cleaning:\", df.shape[0].compute())\n",
        "client.close()\n",
        "cluster.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NwkY3D07hxl",
        "outputId": "ad9e7a1d-df66-4c40-c164-4866f51c8cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:37325\n",
            "INFO:distributed.scheduler:  dashboard at:           127.0.0.1:40595\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:35315'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:41737'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:40027', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:40027\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:36266\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:38837', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:38837\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:36258\n",
            "INFO:distributed.scheduler:Receive client connection: Client-f4aef913-0855-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:36274\n",
            "INFO:distributed.scheduler:Remove client Client-f4aef913-0855-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:36274; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-f4aef913-0855-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-f4aef913-0855-11ee-86c6-0242ac1c000c\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:35315'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:41737'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:36266; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:40027', name: 1, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:40027\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:36258; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:38837', name: 0, status: closing, memory: 0, processing: 0>\n",
            "INFO:distributed.core:Removing comms to tcp://127.0.0.1:38837\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.scheduler:Scheduler closing...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df.to_parquet('/content/drive/MyDrive/Datasets/NYC_Taxi/cleaned_data.parquet', engine='pyarrow')\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wpHmoST-oXK"
      },
      "source": [
        "# Building A Time Series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjW5Rhbx8v6E"
      },
      "outputs": [],
      "source": [
        "df['pickup_timestamp'] = dd.to_datetime(df['tpep_pickup_datetime'])\n",
        "df['dropoff_timestamp'] = dd.to_datetime(df['tpep_dropoff_datetime'])\n",
        "cluster = LocalCluster()\n",
        "client = Client()\n",
        "df = df.map_partitions(lambda partition: partition.set_index(['pickup_timestamp']))\n",
        "cluster.close()\n",
        "client.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8cQOg-xE5nt"
      },
      "source": [
        "## Saving the Time Series on the disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep_nVbd0aBlb"
      },
      "outputs": [],
      "source": [
        "df.to_parquet('/content/drive/MyDrive/Datasets/NYC_Taxi/cleaned_ts', engine='pyarrow')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading The data from the disk "
      ],
      "metadata": {
        "id": "Hh6xeAY2j2y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = dd.read_parquet('/content/drive/MyDrive/Datasets/NYC_Taxi/cleaned_data.parquet*.parquet', engine='pyarrow')"
      ],
      "metadata": {
        "id": "2nErgS-rj2Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgjnP_n5FC6a"
      },
      "source": [
        "#Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "locations_df = pd.read_csv('/content/drive/MyDrive/Datasets/Copy of taxi_zone_lookup.csv')"
      ],
      "metadata": {
        "id": "LZsoHdCfevkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_zones(partition,column):\n",
        "    # Access the Pandas DataFrame within each partition\n",
        "    local_df = partition[0]\n",
        "    # Perform the join operation to get the 'zone' values\n",
        "    merged_df = local_df.merge(locations_df, left_on=column,right_on = 'LocationID', how='left')\n",
        "    return merged_df[['Zone','Borough','service_zone']]"
      ],
      "metadata": {
        "id": "6is04Dx6gPCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source Zone && Source Borough && Source Service Zone"
      ],
      "metadata": {
        "id": "ui6aNPLxdN_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df[['Source_Zone','Source_Borough','Source_Service_Zone']] = df.map_partitions(lambda partition: map_zones(partition,'PULocationID'), meta=({'Source_Zone':'object','Source_Borough':'object','Source_Service_Zone':'object'}))\n",
        "\n",
        "\n",
        "\n",
        "cluster.close()\n",
        "client.close()\n"
      ],
      "metadata": {
        "id": "Q40EJ6lydQ0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Destionation Zone && Destionation Borough && Destionation Service Zone"
      ],
      "metadata": {
        "id": "QDC0uN7ihuT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df[['Destination_Zone','Destination_Borough','Destination_Service_Zone']] = df.map_partitions(lambda partition: map_zones(partition,'DOLocationID'), meta=({'Destination_Zone':'object','Destination_Borough':'object','Destination_Service_Zone':'object'}))\n",
        "\n",
        "\n",
        "cluster.close()\n",
        "client.close()"
      ],
      "metadata": {
        "id": "FXjulh137cUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Location Pair"
      ],
      "metadata": {
        "id": "ykOc8saiUJst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Location_Pair'] = df['Source Zone'].astype(str) + ', ' + df['Destination Zone'].astype(str)\n",
        "\n",
        "df = df.sort_values('Location_Pair')"
      ],
      "metadata": {
        "id": "Y0aJPplbUSfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Payment Name Type\n"
      ],
      "metadata": {
        "id": "D0CAFPfmVlhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "payment_mapping = {\n",
        "    1: 'Credit card',\n",
        "    2: 'Cash',\n",
        "    3: 'No charge',\n",
        "    4: 'Dispute',\n",
        "    5: 'Unknown',\n",
        "    6: 'Voided trip'\n",
        "}\n",
        "\n",
        "def map_payment_name(partition):\n",
        "  \n",
        "    payment_method = partition['payment_type']\n",
        "    payment_names = payment_method.map(payment_mapping)\n",
        "    \n",
        "    return payment_names"
      ],
      "metadata": {
        "id": "kRfSI0haVlUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df['payment_name'] = df.map_partitions(map_payment_name, meta=('payment_type_name', 'object'))\n",
        "\n",
        "cluster.close()\n",
        "client.close()"
      ],
      "metadata": {
        "id": "YOetdaPiW07S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vendor"
      ],
      "metadata": {
        "id": "zqdDSohuW_8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vendor_mapping = {\n",
        "    1: 'Creative Mobile Technologies, LLC',\n",
        "    2: 'VeriFone Inc',\n",
        "  \n",
        "}\n",
        "\n",
        "def map_vendor_name(partition):\n",
        "  \n",
        "    vendor_id = partition['VendorID']\n",
        "    vendor_names = vendor_id.map(payment_mapping)\n",
        "    \n",
        "    return vendor_names"
      ],
      "metadata": {
        "id": "V6ZkuULpXH0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df['VendorID'] = df.map_partitions(map_vendor_name, meta=('Vendor_Name', 'object'))\n",
        "\n",
        "cluster.close()\n",
        "client.close()"
      ],
      "metadata": {
        "id": "nMNf33UEaoSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trip Class"
      ],
      "metadata": {
        "id": "5dQEjAo-a4AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "top_20_location_pairs = df['location_pair'].value_counts().nlargest(20)\n",
        "top_20_location_pairs = top_20_location_pairs.compute()\n",
        "\n",
        "cluster.close()\n",
        "client.close()"
      ],
      "metadata": {
        "id": "X8v3DZaZctXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3bgHrzDQrM1"
      },
      "source": [
        "## Trip Duration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_trip_duration(pickup_datetime, dropoff_datetime):\n",
        "    return (dropoff_datetime - pickup_datetime).dt.total_seconds()/60"
      ],
      "metadata": {
        "id": "a7PHGWa8-kI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-e4sB1aFFb-"
      },
      "outputs": [],
      "source": [
        "cluster = LocalCluster()\n",
        "\n",
        "client = Client(cluster)\n",
        "\n",
        "\n",
        "df['trip_duration'] = df.map_partitions(\n",
        "    lambda partition: compute_trip_duration(partition['tpep_pickup_datetime'], partition['tpep_dropoff_datetime']),\n",
        "    meta=('trip_duration', 'float64')\n",
        ")\n",
        "\n",
        "\n",
        "client.close()\n",
        "cluster.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trip Distance"
      ],
      "metadata": {
        "id": "fcAphEYFbDWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNfFnjpKWjyh"
      },
      "outputs": [],
      "source": [
        "conversion_factor = 1.60934\n",
        "\n",
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "df['trip_distance_km'] = df['trip_distance'] * conversion_factor\n",
        "\n",
        "client.close()\n",
        "cluster.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VWGPJ-xOqOdcgQbhrUftWi6Cs22F7K0v",
      "authorship_tag": "ABX9TyOkl8+Tc1hD6Y3QFbkpoSqo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}